{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "93fbc2cb",
      "metadata": {
        "id": "93fbc2cb"
      },
      "source": [
        "# The Synthetic Radio Host - Wiki-talks ðŸŽ™ï¸\n",
        "\n",
        "**Winter 30 Hackathon | Task 1**\n",
        "\n",
        "Convert any Wikipedia article into a natural-sounding 2-minute Hinglish radio conversation using Google Gemini and ElevenLabs V3.\n",
        "\n",
        "### Features\n",
        "- Natural Hinglish (Hindi-English) conversations\n",
        "- Interruptions, filler words, laughter\n",
        "- Three conversation styles: RJ, Business, Teams"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0413505",
      "metadata": {
        "id": "c0413505"
      },
      "source": [
        "## Setup\n",
        "\n",
        "### Add API Keys to Colab Secrets\n",
        "1. Click the **ðŸ”‘ key icon** in the left sidebar (or go to Runtime > Manage secrets)\n",
        "2. Add these two secrets:\n",
        "   - `GEMINI_API_KEY` - Your Google Gemini API key\n",
        "   - `ELEVEN_API_KEY` - Your ElevenLabs API key\n",
        "3. Toggle \"Notebook access\" ON for both\n",
        "\n",
        "Then run all cells below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e290087",
      "metadata": {
        "id": "0e290087",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "!pip install google-generativeai wikipedia-api requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93abeec1",
      "metadata": {
        "id": "93abeec1",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Configuration for The Synthetic Radio Host - Wiki-talks\n",
        "\n",
        "import os\n",
        "\n",
        "# ElevenLabs V3 Model Configuration\n",
        "MODEL_ID = \"eleven_v3\"\n",
        "\n",
        "# ElevenLabs API Endpoint\n",
        "ELEVENLABS_BASE_URL = \"https://api.elevenlabs.io/v1/text-to-dialogue\"\n",
        "\n",
        "# Voice Cast Mapping (Host and Guest voices)\n",
        "VOICE_CAST = {\n",
        "    \"Host\": \"tJadXrsBtUAO6pGZKpyW\",\n",
        "    \"Guest\": \"hczKB0VbXLcBTn17ShYS\"\n",
        "}\n",
        "\n",
        "# Conversation Variants with Hinglish-focused System Prompts\n",
        "VARIANTS = {\n",
        "    \"RJ\": \"\"\"You are a Bollywood Radio Scriptwriter. Convert the summary into a dialogue (Hinglish).\n",
        "STRICT V3 AUDIO RULES:\n",
        "1. Do NOT use SSML (no <break>, no <prosody>).\n",
        "2. Use Audio Tags inside the text: [laughs], [sighs], [whispers], [clears throat], [gasps].\n",
        "3. Use Punctuation for Pacing: Use ... for hesitation.\n",
        "4. Use CAPS for emphasis (e.g., 'Arre BAS! Stop it!').\n",
        "5. Interruptions: To simulate an interruption, end one speaker's line with - and start the next with [fast].\n",
        "6. Output: Strict JSON. No Markdown ticks.\n",
        "\n",
        "Style: Casual, engaging radio host style. Use natural Hinglish with filler words like \"achcha\", \"hain na\", \"yaar\", \"waah\".\n",
        "Make it sound like a fun, energetic radio show conversation. Include natural laughter, reactions, and interruptions.\"\"\",\n",
        "\n",
        "    \"Business\": \"\"\"You are a Bollywood Radio Scriptwriter. Convert the summary into a dialogue (Hinglish).\n",
        "STRICT V3 AUDIO RULES:\n",
        "1. Do NOT use SSML (no <break>, no <prosody>).\n",
        "2. Use Audio Tags inside the text: [laughs], [sighs], [whispers], [clears throat], [gasps].\n",
        "3. Use Punctuation for Pacing: Use ... for hesitation.\n",
        "4. Use CAPS for emphasis (e.g., 'Arre BAS! Stop it!').\n",
        "5. Interruptions: To simulate an interruption, end one speaker's line with - and start the next with [fast].\n",
        "6. Output: Strict JSON. No Markdown ticks.\n",
        "\n",
        "Style: Professional Hinglish business discussion. Maintain a respectful, informative tone while using natural Hinglish.\n",
        "Use business-appropriate filler words like \"achcha\", \"theek hai\", \"sahi hai\". Keep interruptions minimal and professional.\"\"\",\n",
        "\n",
        "    \"Teams\": \"\"\"You are a Bollywood Radio Scriptwriter. Convert the summary into a dialogue (Hinglish).\n",
        "STRICT V3 AUDIO RULES:\n",
        "1. Do NOT use SSML (no <break>, no <prosody>).\n",
        "2. Use Audio Tags inside the text: [laughs], [sighs], [whispers], [clears throat], [gasps].\n",
        "3. Use Punctuation for Pacing: Use ... for hesitation.\n",
        "4. Use CAPS for emphasis (e.g., 'Arre BAS! Stop it!').\n",
        "5. Interruptions: To simulate an interruption, end one speaker's line with - and start the next with [fast].\n",
        "6. Output: Strict JSON. No Markdown ticks.\n",
        "\n",
        "Style: Sports/team-focused energetic Hinglish conversation. High energy, passionate discussion about teams, players, and sports.\n",
        "Use enthusiastic filler words like \"waah\", \"arey yaar\", \"kya baat hai\", \"mast hai\". Include excitement, reactions, and natural interruptions.\"\"\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df545672",
      "metadata": {
        "id": "df545672",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import requests\n",
        "from google import genai\n",
        "import wikipediaapi  # Package: wikipedia-api (install via: pip install wikipedia-api)\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "\n",
        "class WikiScraper:\n",
        "    \"\"\"Handles Wikipedia content extraction with error handling\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.wiki = wikipediaapi.Wikipedia(\n",
        "            user_agent='wiki-talks/1.0 (https://github.com/purugoyal-ril/wiki-talks)',\n",
        "            language='en'\n",
        "        )\n",
        "\n",
        "    def scrape(self, url: str, mode: str = \"fast\") -> Tuple[Optional[str], Optional[str]]:\n",
        "        \"\"\"\n",
        "        Scrape Wikipedia content from URL\n",
        "\n",
        "        Args:\n",
        "            url: Wikipedia article URL\n",
        "            mode: \"fast\" (summary only) or \"pro\" (sections, capped at 4000 words)\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (content, error_message). content is None if error occurred.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Extract page title from URL\n",
        "            page_title = self._extract_title_from_url(url)\n",
        "            if not page_title:\n",
        "                return None, \"Invalid Wikipedia URL format\"\n",
        "\n",
        "            # Get page\n",
        "            page = self.wiki.page(page_title)\n",
        "\n",
        "            # Check if page exists\n",
        "            if not page.exists():\n",
        "                return None, f\"Wikipedia page '{page_title}' not found\"\n",
        "\n",
        "            # Handle disambiguation\n",
        "            if 'disambiguation' in page.title.lower():\n",
        "                # Auto-select first option\n",
        "                if page.links:\n",
        "                    first_link = list(page.links.keys())[0]\n",
        "                    page = self.wiki.page(first_link)\n",
        "                    if not page.exists():\n",
        "                        return None, f\"Could not access disambiguation option: {first_link}\"\n",
        "\n",
        "            # Extract content based on mode\n",
        "            if mode.lower() == \"fast\":\n",
        "                content = page.summary\n",
        "            else:  # pro mode\n",
        "                content = self._extract_sections(page, max_words=4000)\n",
        "\n",
        "            if not content or len(content.strip()) < 50:\n",
        "                return None, \"Page content too short or empty\"\n",
        "\n",
        "            return content, None\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle disambiguation and page errors generically\n",
        "            # Note: wikipediaapi doesn't have an exceptions module, so we catch all exceptions\n",
        "            # and check error messages to determine the type\n",
        "            error_str = str(e).lower()\n",
        "            if 'disambiguation' in error_str or 'ambiguous' in error_str:\n",
        "                # Try to auto-select first option from links if we have a page object\n",
        "                try:\n",
        "                    # Try to get the page again to access links\n",
        "                    page_title = self._extract_title_from_url(url)\n",
        "                    if page_title:\n",
        "                        page = self.wiki.page(page_title)\n",
        "                        if hasattr(page, 'links') and page.links:\n",
        "                            first_link = list(page.links.keys())[0]\n",
        "                            selected_page = self.wiki.page(first_link)\n",
        "                            if selected_page.exists():\n",
        "                                content = selected_page.summary if mode.lower() == \"fast\" else self._extract_sections(selected_page, max_words=4000)\n",
        "                                return content, None\n",
        "                except Exception:\n",
        "                    pass\n",
        "                return None, f\"Disambiguation error: {str(e)}\"\n",
        "            elif 'page' in error_str or 'not found' in error_str:\n",
        "                return None, f\"Page error: {str(e)}\"\n",
        "            else:\n",
        "                return None, f\"Error scraping Wikipedia: {str(e)}\"\n",
        "\n",
        "    def _extract_title_from_url(self, url: str) -> Optional[str]:\n",
        "        \"\"\"Extract page title from Wikipedia URL\"\"\"\n",
        "        # Handle various URL formats\n",
        "        patterns = [\n",
        "            r'wikipedia\\.org/wiki/([^?#]+)',\n",
        "            r'wikipedia\\.org/wiki/([^/?#]+)',\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, url)\n",
        "            if match:\n",
        "                title = match.group(1)\n",
        "                # URL decode\n",
        "                title = title.replace('_', ' ')\n",
        "                return title\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _extract_sections(self, page, max_words: int = 4000) -> str:\n",
        "        \"\"\"Extract content from sections, capped at max_words\"\"\"\n",
        "        content_parts = []\n",
        "        word_count = 0\n",
        "\n",
        "        # Add summary first\n",
        "        if page.summary:\n",
        "            words = page.summary.split()\n",
        "            if word_count + len(words) <= max_words:\n",
        "                content_parts.append(page.summary)\n",
        "                word_count += len(words)\n",
        "\n",
        "        # Add sections\n",
        "        for section in page.sections:\n",
        "            if word_count >= max_words:\n",
        "                break\n",
        "\n",
        "            section_title = section.title\n",
        "            section_text = section.text\n",
        "            words = section_text.split()\n",
        "\n",
        "            if word_count + len(words) <= max_words:\n",
        "                content_parts.append(f\"\\n\\n## {section_title}\\n\\n{section_text}\")\n",
        "                word_count += len(words)\n",
        "            else:\n",
        "                # Add partial section\n",
        "                remaining_words = max_words - word_count\n",
        "                partial_text = ' '.join(words[:remaining_words])\n",
        "                content_parts.append(f\"\\n\\n## {section_title}\\n\\n{partial_text}\")\n",
        "                break\n",
        "\n",
        "        return '\\n'.join(content_parts)\n",
        "\n",
        "\n",
        "class ScriptGenerator:\n",
        "    \"\"\"Generates Hinglish conversation scripts using Google Gemini\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str):\n",
        "        \"\"\"\n",
        "        Initialize ScriptGenerator with Gemini API key\n",
        "\n",
        "        Args:\n",
        "            api_key: Google Gemini API key\n",
        "        \"\"\"\n",
        "        self.client = genai.Client(api_key=api_key)\n",
        "        self.model_name = 'gemini-2.5-flash'\n",
        "        # Store generation config for use in generate_content\n",
        "        self.generation_config = {\n",
        "            \"response_mime_type\": \"application/json\",\n",
        "            \"temperature\": 0.8\n",
        "        }\n",
        "\n",
        "    def generate_script(self, text: str, variant: str = \"RJ\", duration: int = 120) -> Tuple[Optional[List[Dict]], Optional[str]]:\n",
        "        \"\"\"\n",
        "        Generate Hinglish conversation script from Wikipedia content\n",
        "\n",
        "        Args:\n",
        "            text: Wikipedia content text\n",
        "            variant: \"RJ\", \"Business\", or \"Teams\"\n",
        "            duration: Target duration in seconds (default 120 for 2 minutes)\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (script_json, error_message). script_json is None if error occurred.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Get variant-specific system prompt\n",
        "            system_prompt = VARIANTS.get(variant, VARIANTS[\"RJ\"])\n",
        "\n",
        "            # Calculate target word count (~150 WPM for conversational)\n",
        "            target_words = int((duration / 60) * 150)  # ~300 words for 2 minutes\n",
        "\n",
        "            # Create user prompt\n",
        "            user_prompt = f\"\"\"Convert the following Wikipedia content into a natural 2-minute Hinglish conversation between Host and Guest.\n",
        "\n",
        "Target: Approximately {target_words} words total for ~{duration} seconds of conversation.\n",
        "\n",
        "Content:\n",
        "{text[:3000]}  # Limit input to avoid token limits\n",
        "\n",
        "Requirements:\n",
        "- Output strict JSON array format: [{{\"speaker\": \"Host\", \"text\": \"...\"}}, {{\"speaker\": \"Guest\", \"text\": \"...\"}}]\n",
        "- Use natural Hinglish (Hindi-English mix)\n",
        "- Include interruptions (end line with -, next starts with [fast])\n",
        "- Use audio tags: [laughs], [sighs], [whispers], [clears throat], [gasps]\n",
        "- Use ... for hesitation\n",
        "- Use CAPS for emphasis\n",
        "- Make it conversational and natural\n",
        "- NO SSML tags\n",
        "- NO markdown code fences in output\"\"\"\n",
        "\n",
        "            # Generate script\n",
        "            response = self.client.models.generate_content(\n",
        "                model=self.model_name,\n",
        "                contents=f\"{system_prompt}\\n\\n{user_prompt}\",\n",
        "                config=self.generation_config\n",
        "            )\n",
        "\n",
        "            # Extract JSON from response\n",
        "            script_text = response.text\n",
        "\n",
        "            # Strip markdown code fences if present\n",
        "            script_text = self._strip_markdown(script_text)\n",
        "\n",
        "            # Parse JSON\n",
        "            script_json = json.loads(script_text)\n",
        "\n",
        "            # Validate structure\n",
        "            if not isinstance(script_json, list):\n",
        "                return None, \"Script must be a JSON array\"\n",
        "\n",
        "            # Validate each entry\n",
        "            for entry in script_json:\n",
        "                if not isinstance(entry, dict):\n",
        "                    return None, \"Each script entry must be a dictionary\"\n",
        "                if \"speaker\" not in entry or \"text\" not in entry:\n",
        "                    return None, \"Each entry must have 'speaker' and 'text' fields\"\n",
        "                if entry[\"speaker\"] not in [\"Host\", \"Guest\"]:\n",
        "                    return None, f\"Speaker must be 'Host' or 'Guest', got: {entry['speaker']}\"\n",
        "\n",
        "            return script_json, None\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            return None, f\"JSON parsing error: {str(e)}\"\n",
        "        except Exception as e:\n",
        "            return None, f\"Error generating script: {str(e)}\"\n",
        "\n",
        "    def _strip_markdown(self, text: str) -> str:\n",
        "        \"\"\"Strip markdown code fences from JSON response\"\"\"\n",
        "        # Remove ```json and ``` markers\n",
        "        text = re.sub(r'^```json\\s*', '', text, flags=re.MULTILINE)\n",
        "        text = re.sub(r'^```\\s*', '', text, flags=re.MULTILINE)\n",
        "        text = re.sub(r'```$', '', text, flags=re.MULTILINE)\n",
        "        return text.strip()\n",
        "\n",
        "\n",
        "class AudioEngine:\n",
        "    \"\"\"Generates audio using ElevenLabs V3 Dialogue API\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize AudioEngine\"\"\"\n",
        "        pass\n",
        "\n",
        "    def generate_dialogue_v3(self, script_json: List[Dict], api_key: str, base_url: Optional[str] = None) -> Tuple[Optional[bytes], Optional[str]]:\n",
        "        \"\"\"\n",
        "        Generate audio using ElevenLabs V3 text-to-dialogue endpoint\n",
        "\n",
        "        Args:\n",
        "            script_json: List of dicts with \"speaker\" and \"text\" keys\n",
        "            api_key: ElevenLabs API key\n",
        "            base_url: Optional custom base URL (defaults to ELEVENLABS_BASE_URL)\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (audio_bytes, error_message). audio_bytes is None if error occurred.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Use provided base_url or default from config\n",
        "            url = base_url or ELEVENLABS_BASE_URL\n",
        "\n",
        "            # Build dialogue_inputs array\n",
        "            dialogue_inputs = []\n",
        "\n",
        "            for line in script_json:\n",
        "                speaker = line.get(\"speaker\", \"Host\")\n",
        "                text = line.get(\"text\", \"\")\n",
        "\n",
        "                # Look up voice_id from VOICE_CAST\n",
        "                voice_id = VOICE_CAST.get(speaker)\n",
        "                if not voice_id:\n",
        "                    return None, f\"Voice ID not found for speaker: {speaker}\"\n",
        "\n",
        "                dialogue_inputs.append({\n",
        "                    \"text\": text,\n",
        "                    \"voice_id\": voice_id\n",
        "                })\n",
        "\n",
        "            # Prepare API request\n",
        "            headers = {\n",
        "                \"xi-api-key\": api_key,\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            }\n",
        "\n",
        "            body = {\n",
        "                \"inputs\": dialogue_inputs,\n",
        "                \"model_id\": MODEL_ID\n",
        "            }\n",
        "\n",
        "            # Make API call\n",
        "            response = requests.post(url, json=body, headers=headers, timeout=120)\n",
        "\n",
        "            # Check response\n",
        "            if response.status_code != 200:\n",
        "                error_msg = f\"ElevenLabs API error: {response.status_code}\"\n",
        "                try:\n",
        "                    error_detail = response.json()\n",
        "                    error_msg += f\" - {error_detail}\"\n",
        "                except:\n",
        "                    error_msg += f\" - {response.text[:200]}\"\n",
        "                return None, error_msg\n",
        "\n",
        "            # Return binary audio content\n",
        "            audio_bytes = response.content\n",
        "            return audio_bytes, None\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            return None, f\"Network error: {str(e)}\"\n",
        "        except Exception as e:\n",
        "            return None, f\"Error generating audio: {str(e)}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef05d3f3",
      "metadata": {
        "id": "ef05d3f3",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import userdata\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"Note: Not running in Colab. Using environment variables for API keys.\")\n",
        "\n",
        "# Cell 3: Configuration and API Keys\n",
        "def get_colab_api_keys():\n",
        "    \"\"\"Get API keys from Colab userdata or environment variables\"\"\"\n",
        "    if IN_COLAB:\n",
        "        try:\n",
        "            gemini_key = userdata.get('GEMINI_API_KEY')\n",
        "            eleven_key = userdata.get('ELEVEN_API_KEY')\n",
        "            return gemini_key, eleven_key\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting API keys from Colab userdata: {e}\")\n",
        "            print(\"\\nTo set API keys in Colab:\")\n",
        "            print(\"1. Go to: Runtime > Manage secrets\")\n",
        "            print(\"2. Add secrets: GEMINI_API_KEY and ELEVEN_API_KEY\")\n",
        "            return None, None\n",
        "    else:\n",
        "        # Local environment: use environment variables\n",
        "        gemini_key = os.environ.get('GEMINI_API_KEY')\n",
        "        eleven_key = os.environ.get('ELEVEN_API_KEY')\n",
        "\n",
        "        if not gemini_key:\n",
        "            print(\"âš ï¸  GEMINI_API_KEY not found in environment variables\")\n",
        "        if not eleven_key:\n",
        "            print(\"âš ï¸  ELEVEN_API_KEY not found in environment variables\")\n",
        "\n",
        "        return gemini_key, eleven_key\n",
        "\n",
        "# Cell 4: Main Pipeline Function\n",
        "def generate_wiki_talk(wikipedia_url: str, variant: str = \"RJ\", mode: str = \"fast\", output_file: str = \"wiki_talk_output.mp3\"):\n",
        "    \"\"\"\n",
        "    Complete pipeline: Wikipedia URL â†’ Script â†’ Audio\n",
        "\n",
        "    Args:\n",
        "        wikipedia_url: Full Wikipedia article URL\n",
        "        variant: \"RJ\", \"Business\", or \"Teams\"\n",
        "        mode: \"fast\" (summary) or \"pro\" (sections)\n",
        "        output_file: Output MP3 filename\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (success: bool, message: str, script_json: list, audio_path: str)\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"The Synthetic Radio Host - Wiki-talks - Generating Hinglish Conversation\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Get API keys\n",
        "    gemini_key, eleven_key = get_colab_api_keys()\n",
        "    if not gemini_key:\n",
        "        return False, \"Gemini API key not found. Please set GEMINI_API_KEY in Colab secrets.\", None, None\n",
        "    if not eleven_key:\n",
        "        return False, \"ElevenLabs API key not found. Please set ELEVEN_API_KEY in Colab secrets.\", None, None\n",
        "\n",
        "    # Step 1: Scrape Wikipedia\n",
        "    print(\"\\n[1/3] Scraping Wikipedia...\")\n",
        "    scraper = WikiScraper()\n",
        "    content, error = scraper.scrape(wikipedia_url, mode)\n",
        "    if error:\n",
        "        return False, f\"Wikipedia scraping failed: {error}\", None, None\n",
        "    print(f\"âœ“ Scraped {len(content)} characters from Wikipedia\")\n",
        "\n",
        "    # Step 2: Generate Script\n",
        "    print(\"\\n[2/3] Generating Hinglish conversation script...\")\n",
        "    script_gen = ScriptGenerator(gemini_key)\n",
        "    script_json, error = script_gen.generate_script(content, variant, duration=120)\n",
        "    if error:\n",
        "        return False, f\"Script generation failed: {error}\", None, None\n",
        "    print(f\"âœ“ Generated script with {len(script_json)} dialogue entries\")\n",
        "\n",
        "    # Display script preview\n",
        "    print(\"\\nScript Preview:\")\n",
        "    for i, entry in enumerate(script_json[:3], 1):\n",
        "        print(f\"  {i}. {entry['speaker']}: {entry['text'][:80]}...\")\n",
        "    if len(script_json) > 3:\n",
        "        print(f\"  ... and {len(script_json) - 3} more entries\")\n",
        "\n",
        "    # Step 3: Generate Audio\n",
        "    print(\"\\n[3/3] Generating audio with ElevenLabs V3...\")\n",
        "    audio_engine = AudioEngine()\n",
        "    audio_bytes, error = audio_engine.generate_dialogue_v3(script_json, eleven_key)\n",
        "    if error:\n",
        "        return False, f\"Audio generation failed: {error}\", script_json, None\n",
        "    print(f\"âœ“ Generated audio ({len(audio_bytes)} bytes)\")\n",
        "\n",
        "    # Save audio file\n",
        "    try:\n",
        "        with open(output_file, 'wb') as f:\n",
        "            f.write(audio_bytes)\n",
        "        print(f\"\\nâœ“ Audio saved to: {output_file}\")\n",
        "        audio_path = os.path.abspath(output_file)\n",
        "    except Exception as e:\n",
        "        return False, f\"Error saving audio file: {str(e)}\", script_json, None\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"âœ“ Success! The Synthetic Radio Host - Wiki-talks generation complete\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return True, \"Success\", script_json, audio_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab2140f9",
      "metadata": {
        "id": "ab2140f9"
      },
      "source": [
        "## Usage\n",
        "\n",
        "### Parameters\n",
        "- **wikipedia_url**: Any Wikipedia article URL\n",
        "- **variant**:\n",
        "  - `\"RJ\"` - Casual radio host style (fun, energetic)\n",
        "  - `\"Business\"` - Professional discussion\n",
        "  - `\"Teams\"` - Sports-focused, high energy\n",
        "- **mode**:\n",
        "  - `\"fast\"` - Uses article summary only\n",
        "  - `\"pro\"` - Uses full sections (up to 4000 words)\n",
        "\n",
        "### Run the cell below to generate!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca73bc47",
      "metadata": {
        "id": "ca73bc47",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Example: Mumbai Indians Wikipedia article\n",
        "    example_url = \"https://en.wikipedia.org/wiki/Mumbai_Indians\"\n",
        "\n",
        "    print(\"The Synthetic Radio Host - Wiki-talks - Example Run\")\n",
        "    print(f\"URL: {example_url}\")\n",
        "    print(f\"Variant: RJ\")\n",
        "    print(f\"Mode: fast\\n\")\n",
        "\n",
        "    success, message, script, audio_path = generate_wiki_talk(\n",
        "        wikipedia_url=example_url,\n",
        "        variant=\"RJ\",\n",
        "        mode=\"fast\",\n",
        "        output_file=\"mumbai_indians_talk.mp3\"\n",
        "    )\n",
        "\n",
        "    if success:\n",
        "        print(f\"\\nâœ“ Script JSON:\")\n",
        "        print(json.dumps(script, indent=2, ensure_ascii=False))\n",
        "        print(f\"\\nâœ“ Audio file: {audio_path}\")\n",
        "        print(\"\\nYou can play the audio file or download it from Colab.\")\n",
        "    else:\n",
        "        print(f\"\\nâœ— Error: {message}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
